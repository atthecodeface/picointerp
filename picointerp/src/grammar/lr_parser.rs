/*a Copyright

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

  http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.

@file    configurating_set.rs
@brief   Part of grammar library
 */

//a Imports
use std::fmt::Display;
use std::fmt::Debug;
use std::hash::Hash;
use std::collections::{HashMap, HashSet};
use super::{Token, Nonterminal, Data, Element, Grammar, GrammarRule, GrammarRulePos, ConfiguratingSet, LRAnalysis};

//a Constants
const DEBUG_LR_PARSE : bool = 1 == 1;

//a TokenInHand
//ti TokenInHand
enum TokenInHand<N:Nonterminal, T:Token, D:Data> {
    /// No token in hand - need to fetch the next one
    None,
    /// Eof - the end of the stream has been reached and only reductions are permitted
    Eof,
    /// Token - has been fetched from the stream
    Token((T, D)),
    /// Nonterminal - has been generated by a reduction
    Nonterminal((N, D))
}

//ii TokenInHand
impl <N:Nonterminal, T:Token, D:Data> TokenInHand<N,T,D> {
    pub fn none() -> Self { Self::None }
    pub fn get(next_token:&mut impl Iterator<Item = (Element<N,T>,D)>) -> Self {
        match next_token.next() {
            None => {
                Self::Eof
            },
            Some((Element::Token(t),d)) => {
                Self::Token((t,d))
            },
            Some((Element::Nonterminal(n),d)) => {
                Self::Nonterminal((n,d))
            },
        }
    }
    pub fn get_if_required(self, next_token:&mut impl Iterator<Item = (Element<N,T>,D)>) -> Self {
        if self.is_none() {Self::get(next_token)} else {self}
    }
    pub fn is_none(&self) -> bool {
        match self {
            Self::None => true,
            _ => false,
        }
    }
    pub fn is_eof(&self) -> bool {
        match self {
            Self::Eof => true,
            _ => false,
        }
    }
    pub fn reduced_to(nonterminal:&N, data:D) -> Self {
        Self::Nonterminal((*nonterminal, data))
    }
    pub fn as_element(&self) -> Element<N,T> {
        match self {
            Self::Token((t,_))       => Element::Token(*t),
            Self::Nonterminal((n,_)) => Element::Nonterminal(*n),
            _ => {
                panic!("Attempt to retrieve Element from a TokenInHand that is EOF or None {}",self);
            }
        }
    }
    pub fn data(self) -> Option<D> {
        match self {
            Self::Token((_,d)) => Some(d),
            Self::Nonterminal((_,d)) => Some(d),
            _ => None,
        }
    }
    pub fn borrow_token(&self) -> Option<&T> {
        match self {
            Self::Token((t,_))   => Some(t),
            Self::Eof            => None,
            _ => {
                panic!("Attempt to retrieve token from a TokenInHand that is neither EOF nor a token {}",self);
            }
        }
    }
}
//ip Display for TokenInHand
impl <N:Nonterminal, T:Token, D:Data> std::fmt::Display for TokenInHand<N,T,D> {

    //mp fmt - format for display
    /// Display the token
    fn fmt(&self, f: &mut std::fmt::Formatter) -> std::fmt::Result {
        match self {
            Self::None               => write!(f, "<None>"),
            Self::Eof                => write!(f, "<eof>"),
            Self::Token((t,d))       => write!(f, "{}:{}", t, d),
            Self::Nonterminal((n,d)) => write!(f, "{}:{}", n, d),
        }
    }

    //zz All done
}

//ip Debug for TokenInHand
impl <N:Nonterminal, T:Token, D:Data> std::fmt::Debug for TokenInHand<N,T,D> {

    //mp fmt - format for display
    /// Display the token
    fn fmt(&self, f: &mut std::fmt::Formatter) -> std::fmt::Result {
        match self {
            Self::None               => write!(f, "<None>"),
            Self::Eof                => write!(f, "<eof>"),
            Self::Token((t,d))       => write!(f, "{}:{}", t, d),
            Self::Nonterminal((n,d)) => write!(f, "{}:{}", n, d),
        }
    }

    //zz All done
}

//tt Parser
pub trait Parser<F, N:Nonterminal, T:Token, D:Data> {
    //fi find_shift_state
    /// Find the index of the state to shift to from a specified state given an element
    fn find_shift_state(&self, state:usize, e:&Element<N,T>) -> Option<&usize>;

    //fi find_reduce_rule
    /// Find the reduce rule from a state given a lookahed token (None if end of token stream)
    fn find_reduce_rule(&self, state:usize, e:Option<&T>) -> Option<&GrammarRule<F,N,T>>;

    //fi is_goal_rule
    fn is_goal_rule(&self, rule:&GrammarRule<F,N,T>) -> bool;

    //mp parse
    ///  [0]        []      . [X + X ;]    s[X]
    ///  [0 5]      [X]     . [+ X ;]      r(9)
    ///  [0]        []      2 [+ X ;]      s(2)
    ///  [0 4]      [2]     . [+ X ;]      r(5)
    ///  [0]        []      1 [+ X ;]      s(1)
    ///  [0 3]      [1]     . [+ X ;]      r(2)
    ///  [0]        []      0 [+ X ;]      s(0)
    ///  [0 2]      []      . [+ X ;]      s(+)
    ///  [0 2 9]    [0 +]   . [X ;]        s(X)
    ///  [0 2 9 5]  [0 + X] . [;]         r(9)
    ///  [0 2 9]    [0 + 2] 2 [;]        s(2)
    ///  [0 2 9 4]  [0 + 2] . [;]        r(5)
    ///  [0 2 9]    [0 + 1] 1 [;]        s(1)
    ///  [0 2 9 14] [0 + 1] . [;]        r(3)
    ///  [0]        [.]     0 [;]        s(0)
    ///  [0 2]      [0]     . [;]        r(1)
    ///  [0]        []      E [;]        s(E)
    ///  [0 1]      [E]     . [;]        s(;)
    ///  [0 1 7]    [E ;]   . []         r(0)
    ///  [0]        []      C []
    fn parse(&self, next_token:&mut impl Iterator<Item = (Element<N,T>,D)>) -> Result<D, String> {
        let mut i = 0;
        let mut stack      = Vec::new();
        let mut token_stack = Vec::new();
        stack.push(0);
        let mut nonterminal_in_hand = TokenInHand::none();
        let mut token_lookahead     = TokenInHand::get(next_token);
        loop {
            token_lookahead = token_lookahead.get_if_required(next_token);
            if DEBUG_LR_PARSE {println!("Stack {:?} token stack {:?} nonterminal_in_hand {:?} next token {}", stack, token_stack, nonterminal_in_hand, token_lookahead);}
            let state = stack.pop().unwrap();
            let token = if nonterminal_in_hand.is_none() {&token_lookahead} else {&nonterminal_in_hand};
            if DEBUG_LR_PARSE {println!("State {} Token {}", state, token);}
            let opt_shift_state =
                if token.is_eof() { None } else { self.find_shift_state(state, &token.as_element()).map(|x| *x) };
            let opt_reduce_rule = self.find_reduce_rule(state, token_lookahead.borrow_token());
            match opt_shift_state { // Shift over reduce
                Some(next_state) => {
                    stack.push(state);
                    stack.push(next_state);
                    if nonterminal_in_hand.is_none() {
                        token_stack.push(token_lookahead);
                        token_lookahead = TokenInHand::none();
                    } else {
                        token_stack.push(nonterminal_in_hand);
                        nonterminal_in_hand = TokenInHand::none();
                    }
                    if DEBUG_LR_PARSE {println!("Shift to {}", next_state);}
                },
                None => { // Try to reduce
                    match opt_reduce_rule {
                        Some(rule) => {
                            stack.push(state);
                            if DEBUG_LR_PARSE {println!("Reduce by {}", rule);}
                            let mut data_for_fn = Vec::new();
                            for j in 0..rule.length() {
                                stack.pop();
                                data_for_fn.push(token_stack.pop().unwrap().data().unwrap());
                            }
                            // data.reverse();
                            // data = reduce_rule.rule_fn(data);
                            let data = data_for_fn.pop().unwrap();
                            nonterminal_in_hand = TokenInHand::reduced_to(rule.borrow_nonterminal(), data);
                            if self.is_goal_rule(rule) { break; }
                        },
                        None => {
                            return Err(format!("Parse error"));
                        },
                    }
                }
            }
        }
        Ok(nonterminal_in_hand.data().unwrap())
    }
    /*
    //mp analyze
    def analyze(self):
        for s in self.states:
            s.analyze()
            pass
        pass
    //mp generate_graph
    def generate_graph(self):
        self.configurating_set.repr_start = ""
        self.configurating_set.repr_sep   = "\\n"
        self.configurating_set.repr_end   = ""
        g = graph(self.grammar.name)
        nodes = {}
        for s in self.states:
            nodes[s] = g.add_node(str(s))
            if "shift-reduce" in s.conflicts:
                nodes[s].style="filled"
                nodes[s].color="orange"
                pass
            if "reduce-reduce" in s.conflicts:
                nodes[s].style="filled"
                nodes[s].color="red"
                pass
            pass
        for s in self.states:
            for ne in s.targets:
                t = s.targets[ne]
                g.add_transition(nodes[s],nodes[t],ne[1])
            pass
        return g
    //mp get_parse_token
    def get_parse_token(self,tokens,i):
        if (i>=len(tokens)): return (("eof","eof"), None)
        td = tokens[i]
        if ":" not in td[1:]: return (("token", td), None)
        td = td.split(":")
        return (("token", td[0]), td[1])
    //mp parse
    def parse(self, tokens, verbose=False):
        s = self.states[0]
        i = 0
        stack = []
        stack.append(s)
        data_stack = []
        t = self.get_parse_token(tokens,i)
        while True:
            s = stack[-1]
            # Attemp to shift from current state (top of state stack) with token
            ns = s.find_target(t[0])
            if ns is not None:
                stack.append(ns)
                data_stack.append(t[1])
                print "Shift to", ns
                if (t[0][0]=="token"):
                    i += 1
                    pass
                t = self.get_parse_token(tokens,i)
                continue
            # cannot shift... try to reduce
            reduce_rule = None
            for rp in s.rule_positions:
                if rp[0].element(rp[1]) is None:
                    reduce_rule = rp[0]
                    pass
                pass
            if reduce_rule:
                if reduce_rule.length()>0:
                    data = []
                    for j in range(reduce_rule.length()):
                        s = stack.pop()
                        data.append(data_stack.pop())
                        pass
                    data.reverse()
                else:
                    data = t[1]
                    pass
                print "Reduce by rule",reduce_rule,reduce_rule.length(),data
                data = reduce_rule.rule_fn(data)
                t = (("nonterminal",reduce_rule.nonterminal),data)
                print "Reduced to ",t
                if reduce_rule==self.grammar.production_rules[self.grammar.goal].rules[0]:
                    break
                continue
            print "*"*80
            print "Parse error"
            return (t,i)
            pass
        return (t, i)
    //mp parse_find_shift_state
    def parse_find_shift_state(self, token_in_hand, tokens, stack, n):
        s = stack[-1]
        ns = s.find_target(token_in_hand[0])
        if ns is None: return None
        return (ns, token_in_hand[1], token_in_hand[0][0]=="token")
    //mp parse_find_reduce_rule
    def parse_find_reduce_rule(self, token_in_hand, tokens, stack, n):
        """
        Assumes no reduce-reduce conflicts - finds first (if any) reduce rule
        """
        s = stack[-1]
        for rp in s.rule_positions:
            if rp[0].element(rp[1]) is None:
                return rp[0]
                pass
            pass
        return None
    //mp parse
    def parse(self, tokens, verbose=False):
        s = self.states[0]
        i = 0
        stack = []
        stack.append(s)
        data_stack = []
        token_in_hand = None
        while True:
            if token_in_hand is None:
                token_in_hand = self.get_parse_token(tokens,i)
                pass
            if verbose: print "Token in hand %s"%(str(token_in_hand))
            shift_state_consume_token = self.parse_find_shift_state(token_in_hand, tokens, stack, i)
            if shift_state_consume_token is not None:
                (ns, t, tc) = shift_state_consume_token
                stack.append(ns)
                data_stack.append(t)
                if tc: i = i+1
                token_in_hand = None
                if verbose: print "Shift with token %s to state %s consumed %d (position %d)"%(str(t),str(ns),tc,i)
                continue
            # cannot shift... try to reduce
            reduce_rule = self.parse_find_reduce_rule(token_in_hand, tokens, stack, i)
            if reduce_rule:
                if verbose: print "Reduce with rule %s (in hand %s, stack %s)"%(str(reduce_rule), str(token_in_hand), str(data_stack))
                if reduce_rule.length()>0:
                    data = []
                    for j in range(reduce_rule.length()):
                        s = stack.pop()
                        data.append(data_stack.pop())
                        pass
                    data.reverse()
                else:
                    die# - do not support empty rules here
                    t = self.get_parse_token(tokens,i)
                    data = t[1]
                    pass
                data = reduce_rule.rule_fn(data)
                token_in_hand = (("nonterminal",reduce_rule.nonterminal),data)
                if verbose: print "Reduced to ",token_in_hand
                if reduce_rule==self.grammar.production_rules[self.grammar.goal].rules[0]:
                    break
                continue
            print "*"*80
            print "Parse error"
            return (token_in_hand,i)
            pass
        return (token_in_hand, i)
    //mp generate_parse_data
    def generate_parse_data(self, parse_data):
        """
        The parse table is a list of states

        In an LR(0) parser the states have entries for each 'token in
        hand'.

        An entry can be to shift to another state - in this case a
        string token may be consumed but a nonterminal is not
        consumed, but the token is pushed onto the data stack, the
        next state number is pushed onto the state stack, and parsing
        continues from there.

        Alternatively an entry can be a reduction - with LR(0) and no
        reduce-reduce conflicts (unambiguous LR(0) grammar) there is
        one reduction possible. To permit real grammars to be handled,
        shift-reduce conflicts are resolved in favor of shift. So, the
        reduction entry is a last resort, and there is only one
        reduction possible.

        The reduction is a reduction by 'n' items on the data/state
        stack, to produce a new nonterminal in hand. This invokes a
        rule function with the top 'n' items of the data stack, and
        uses the result of that function as the data portion of the
        token in hand.

        Hence the table has a set of shifts - which is effectively a
        dictionary of terminal/nontermial -> state mappings - and a
        single reduction of size 'n' to nonterminal 't' with rule
        (function identifier) 'r'.

        For a small parse program in C the states can be compressed as
        desired.

        In this method, 'parse_data' must be a class that supplies an
        'add_state' method that returns a parse_data state instance
        for the state in the parse_data (given an analysis state
        handle). The parse_data state instance itself must have two
        methods: an 'add_reduce_rule' method, which is given a grammar
        rule as an argument; and an add_target method that is given a
        typed_token and a parse_data target state, for shifting.
        """
        pd_states = {}
        for s in self.states:
            pd_states[s] = parse_data.add_state(s)
            pass
        for s in self.states:
            pd_states[s].add_reduce_rule(self.parse_find_reduce_rule(None,[],[s],0))
            for te in s.targets:
                pd_states[s].add_target(te, pd_states[s.targets[te]])
                pass
            pass
        return parse_data
    //mp All done
    pass
     */
}

